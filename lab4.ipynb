{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# location of the data set. Name files with year\n",
    "fileLocation = '/Code/spark/LAB4/data/200*.csv'\n",
    "\n",
    "# number of trees in forest\n",
    "nbrOfTreesInForest = [4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "# Create spark session\n",
    "spark = SparkSession.builder.appName(\"theappname\").getOrCreate()\n",
    "# Load data from files\n",
    "df = spark.read.csv(fileLocation, mode=\"DROPMALFORMED\", inferSchema=True, header = True)\n",
    "\n",
    "# During debug just load a fraction of the sample dataset to reduce computing time\n",
    "# df = df.sample(fraction=0.01)\n",
    "\n",
    "from pyspark.sql.functions import  length, lpad\n",
    "from pyspark.sql.types import IntegerType\n",
    "# Do first filtering \n",
    "selection = df\\\n",
    "    .where((df.Diverted == 0) & (df.CancellationCode.isNull()) & (df.TailNum.rlike(\"^([A-Z]|[a-z]|[0-9])\"\n",
    "                                                                                                                  \"+$\")) & ((length(df.DepTime) == 4) | (length(df.DepTime) == 3)) & (length(df.ArrTime) == 4) | (length(df.ArrTime) == 3))\\\n",
    "    .where(df['TailNum'].isNotNull())\\\n",
    "    .withColumn(\"DepTime\", when(length(df.DepTime) == 3, lpad(df['DepTime'], 4,'0')).otherwise(df['DepTime']))\\\n",
    "    .withColumn(\"ArrTime\", when(length(df.ArrTime) == 3, lpad(df['ArrTime'], 4,'0')).otherwise(df['ArrTime']))\\\n",
    "    .sort(asc('Year'), 'Month', 'DayofMonth', 'ArrTime')\\\n",
    "    .withColumn(\"ArrDelay\", df.ArrDelay.cast(IntegerType()))\\\n",
    "    .withColumn(\"DepDelay\", df[\"DepDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"CarrierDelay\", df[\"CarrierDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"WeatherDelay\", df[\"WeatherDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"NASDelay\", df[\"NASDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"SecurityDelay\", df[\"SecurityDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"LateAircraftDelay\", df[\"LateAircraftDelay\"].cast(IntegerType()))\\\n",
    "    .fillna(0, subset=['ArrDelay', 'DepDelay', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay' ])\n",
    "\n",
    "from pyspark.sql.types import BinaryType\n",
    "\n",
    "# Define the FFA (Federal Aviation Administration) function\n",
    "udf(returnType=BinaryType())\n",
    "IsLate  = lambda x : x[\"ArrDelay\"] > 15\n",
    "\n",
    "# Create a new column 'IsLate' stating that the flight was considered delay or not\n",
    "selection = selection\\\n",
    "    .withColumn(\"IsLate\", (IsLate(selection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert to pandas since we a running on a single node and the fact that I wanted to learn about pandas\n",
    "basePanda = selection.toPandas()\n",
    "\n",
    "# remove the dataframe from memory\n",
    "selection.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode test columns into new ones and drop the original \n",
    "lb_make = LabelEncoder()\n",
    "basePanda['Origin_code'] = lb_make.fit_transform (basePanda['Origin'])\n",
    "basePanda['Dest_code'] = lb_make.fit_transform (basePanda['Dest'])\n",
    "basePanda['UniqueCarrier_code'] = lb_make.fit_transform (basePanda['UniqueCarrier'])\n",
    "basePanda['TailNum_code'] = lb_make.fit_transform (basePanda['TailNum'])\n",
    "basePanda['DepTime_code'] = lb_make.fit_transform (basePanda['DepTime'])\n",
    "basePanda['TaxiOut_code'] = lb_make.fit_transform (basePanda['TaxiOut'])\n",
    "basePanda['DepTimeHour'] = lb_make.fit_transform (basePanda['DepTime'].str[0:2])    \n",
    "basePanda = basePanda.drop('Origin', axis = 1) \n",
    "basePanda = basePanda.drop('Dest', axis = 1)\n",
    "basePanda = basePanda.drop('UniqueCarrier', axis = 1) \n",
    "basePanda = basePanda.drop('TailNum', axis = 1) \n",
    "basePanda = basePanda.drop('CancellationCode', axis = 1)\n",
    "basePanda = basePanda.drop('Cancelled', axis = 1)\n",
    "basePanda = basePanda.drop('ArrTime', axis = 1)\n",
    "basePanda = basePanda.drop('DepTime', axis = 1)\n",
    "basePanda = basePanda.drop('TaxiOut', axis = 1)\n",
    "basePanda = basePanda.drop('ActualElapsedTime', axis = 1)\n",
    "basePanda = basePanda.drop('CRSElapsedTime', axis = 1)\n",
    "basePanda = basePanda.drop('AirTime', axis = 1)\n",
    "basePanda = basePanda.drop('TaxiIn', axis = 1)\n",
    "# extract the labels column to a separate panda and convert to numpy array\n",
    "labelsPanda  = basePanda['IsLate']\n",
    "labels = np.array(labelsPanda)\n",
    "features = basePanda.drop('IsLate', axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "corr = features.corr()\n",
    "corr = corr.round(2)\n",
    "plt.figure(figsize=(14,12))\n",
    "sb.heatmap(corr, annot=True, cmap='RdBu_r', linewidth=0.5, center=0.1)\n",
    "plt.savefig('heatmap.png',  dpi=100)\n",
    "plt.show()\n",
    "\n",
    "corr_target= np.abs(corr[\"DepDelay\"])\n",
    "# Select the features with a correlation_target larger than 0.2\n",
    "# The 0.1 might be a bit low but as the number of features is low \n",
    "# We can be a bit greedy and select a low limit (many features)\n",
    "selected_features_filter_method= corr_target[corr_target>0.2]\n",
    "print(\"Features selected by filter method\")\n",
    "print(selected_features_filter_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the ArrDelay as we do not need anymore\n",
    "features = features.drop('ArrDelay', axis = 1)\n",
    "\n",
    "# Start the forward selection from \n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sfs = SFS(LinearRegression(),\n",
    "           k_features=6,\n",
    "           forward=True)\n",
    "\n",
    "sfs.fit(features, labels)\n",
    "\n",
    "selected_features_forward_selection = list(sfs.k_feature_names_)\n",
    "print(\"Features selected by wrapper method - forward selection\")\n",
    "print(selected_features_forward_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.savefig('sfs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert from pandas to array to match the 'train_test_split' method\n",
    "reduced_features = np.array(features[selected_features_forward_selection])\n",
    "\n",
    "# split the features/labels into train and test sets \n",
    "train_features, test_features, train_labels, test_labels = train_test_split(reduced_features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_random_forest(tree_size):\n",
    "    print('Fitting random forest model with {} trees'.format(tree_size))\n",
    "    # Instantiate model with 4 decision trees\n",
    "    rf = RandomForestClassifier(n_estimators = tree_size)\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels);\n",
    "    print(\"Random forest score: {:.4f} \".format(rf.score(test_features, test_labels)))\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_features)\n",
    "    \n",
    "    print(classification_report(test_labels, predictions, target_names=['Not late','Late'], digits=4))\n",
    "    \n",
    "    # calculate the probalistics\n",
    "    rf_probs = rf.predict_proba(test_features)[:, 1]\n",
    "    # calculate the roc auc score to se the performance of the DR\n",
    "    roc_value = roc_auc_score(test_labels, rf_probs)\n",
    "    \n",
    "    print(\"AUC ROC score: {:.4f} \".format(roc_value))\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "for tree_size in nbrOfTreesInForest:\n",
    "    run_random_forest(tree_size)\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}