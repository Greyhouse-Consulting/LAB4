{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"theappname\").getOrCreate()\n",
    "df = spark.read.csv('/Code/spark/LAB4/data/20*.csv', mode=\"DROPMALFORMED\", inferSchema=True, header = True)\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import  length, lpad\n",
    "from pyspark.sql.types import IntegerType\n",
    "selection = df\\\n",
    "    .where((df.Diverted == 0) & (df.CancellationCode.isNull()) & (df.TailNum.rlike(\"^([A-Z]|[a-z]|[0-9])\"\n",
    "                                                                                                                  \"+$\")) & ((length(df.DepTime) == 4) | (length(df.DepTime) == 3)) & (length(df.ArrTime) == 4) | (length(df.ArrTime) == 3))\\\n",
    "    .where(df['TailNum'].isNotNull())\\\n",
    "    .withColumn(\"DepTime\", when(length(df.DepTime) == 3, lpad(df['DepTime'], 4,'0')).otherwise(df['DepTime']))\\\n",
    "    .withColumn(\"ArrTime\", when(length(df.ArrTime) == 3, lpad(df['ArrTime'], 4,'0')).otherwise(df['ArrTime']))\\\n",
    "    .sort(asc('Year'), 'Month', 'DayofMonth', 'ArrTime')\\\n",
    "    .withColumn(\"ArrDelay\", df.ArrDelay.cast(IntegerType()))\\\n",
    "    .withColumn(\"DepDelay\", df[\"DepDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"CarrierDelay\", df[\"CarrierDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"WeatherDelay\", df[\"WeatherDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"NASDelay\", df[\"NASDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"SecurityDelay\", df[\"SecurityDelay\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"LateAircraftDelay\", df[\"LateAircraftDelay\"].cast(IntegerType()))\\\n",
    "    .fillna(0, subset=['ArrDelay', 'DepDelay', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay' ])\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import lag\n",
    "from pyspark.sql.types import BinaryType\n",
    "from pyspark.sql import Window\n",
    "#w = Window.orderBy(\"Year\", \"Month\", \"DayofMonth\", \"ArrTime\")\n",
    "w = Window.partitionBy (\"Year\", \"Month\", \"DayofMonth\", \"ArrTime\").orderBy(\"Year\", \"Month\", \"DayofMonth\", \"ArrTime\")\n",
    "\n",
    "udf(returnType=BinaryType())\n",
    "IsLate  = lambda x : x[\"ArrDelay\"] > 15\n",
    "\n",
    "base = selection \\\n",
    "    .withColumn(\"NbrOfPreviousLateFlights\",(lag(selection['ArrDelay'], 1,0).over(w)  > 15 if 1 else 0).cast(IntegerType()) + (lag(selection['ArrDelay'], 2,0).over(w)  > 15 if 1 else 0).cast(IntegerType()) + (lag(selection['ArrDelay'], 3,0).over(w)  > 15 if 1 else 0).cast(IntegerType()))\\\n",
    "    .withColumn(\"IsLate\", (IsLate(selection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "superBasePanda = base.toPandas()\n",
    "from pandas import notnull\n",
    "superBasePanda = superBasePanda.where(superBasePanda['TailNum'].notnull())\n",
    "\n",
    "#spark.catalog.clearCache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas import notnull\n",
    "# Split the data into training and testing sets\n",
    "lb_make = LabelEncoder()\n",
    "basePanda = superBasePanda[['Year', 'Month', 'DayofMonth', 'DepTime', 'Origin', 'Dest', 'TailNum','UniqueCarrier','TaxiOut', 'DepDelay','Distance', 'LateAircraftDelay', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'IsLate']]\n",
    "basePanda = basePanda.dropna()\n",
    "basePanda['Origin_code'] = lb_make.fit_transform (basePanda['Origin'])\n",
    "basePanda['Dest_code'] = lb_make.fit_transform (basePanda['Dest'])\n",
    "basePanda['UniqueCarrier_code'] = lb_make.fit_transform (basePanda['UniqueCarrier'])\n",
    "basePanda['TailNum_code'] = lb_make.fit_transform (basePanda['TailNum'])\n",
    "#basePanda['ArrTime_code'] = lb_make.fit_transform (basePanda['ArrTime'])\n",
    "basePanda['DepTime_code'] = lb_make.fit_transform (basePanda['DepTime'])\n",
    "basePanda['TaxiOut_code'] = lb_make.fit_transform (basePanda['TaxiOut'])\n",
    "basePanda = basePanda.drop('Origin', axis = 1) \n",
    "basePanda = basePanda.drop('Dest', axis = 1)\n",
    "basePanda = basePanda.drop('UniqueCarrier', axis = 1) \n",
    "basePanda = basePanda.drop('TailNum', axis = 1) \n",
    "#basePanda = basePanda.drop('CancellationCode', axis = 1)\n",
    "#basePanda = basePanda.drop('ArrTime', axis = 1)\n",
    "basePanda = basePanda.drop('DepTime', axis = 1)\n",
    "basePanda = basePanda.drop('TaxiOut', axis = 1)\n",
    "labels = np.array(basePanda['IsLate'])\n",
    "  \n",
    "\n",
    "features = basePanda.drop('IsLate', axis = 1) \n",
    "#features = basePanda.get_dummies(features)\n",
    "features = np.array(features)\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 16, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "\n",
    "\n",
    "\n",
    "from time import gmtime, strftime\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "#errors = np.abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "#print('Mean Absolute Error:', np.round(np.mean(errors), 2))\n",
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "\n",
    "rf_probs = rf.predict_proba(test_features)[:, 1]\n",
    "roc_value = roc_auc_score(test_labels, rf_probs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ]
}